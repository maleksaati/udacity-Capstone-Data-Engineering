{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Title\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "\n",
    "The aim of this project is to analyse data of immigration to the United States in addition to integrate with supplementary data which include airport codes, U.S. city demographics, and temperature data to extract insights focusing on the type of visas being issued and the profiles associated.\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in c:\\programs\\python\\python312\\lib\\site-packages (3.5.0)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in c:\\programs\\python\\python312\\lib\\site-packages (from pyspark) (0.10.9.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "The scope is to develop ETL pipelines using Airflow, constructing data warehouses through Redshift databases and S3 data storage as well as defining efficient data models star schema.\n",
    "\n",
    "#### Describe and Gather Data \n",
    "\n",
    "In this project, we'll work with four datasets to complete the project:\n",
    "\n",
    "- I94 Immigration Data: This data comes from the US National Tourism and Trade Office. A data dictionary is included in the workspace. [This](https://travel.trade.gov/research/reports/i94/historical/2016.html) is where the data comes from. Each report contains international visitor arrival statistics by world regions and select countries (including top 20), type of visa, mode of transportation, age groups, states visited (first intended address only), and the top ports of entry (for select countries).\n",
    "- World Temperature Data: This dataset came from Kaggle. You can read more about it [here](https://www.kaggle.com/berkeleyearth/climate-change-earth-surface-temperature-data).\n",
    "- U.S. City Demographic Data: This dataset contains information about the demographics of all US cities. You can read more about it [here](https://public.opendatasoft.com/explore/dataset/us-cities-demographics/export/).\n",
    "- Airport Code Table: This is a simple table of airport codes and corresponding cities. It comes from [here](https://datahub.io/core/airport-codes#data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\t\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.packages\",\"saurfang:spark-sas7bdat:3.0.0-s_2.12\")\\\n",
    ".enableHiveSupport().getOrCreate()\n",
    "df_spark =spark.read.format('com.github.saurfang.sas.spark').load('../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write to parquet\n",
    "df_spark.write.parquet(\"data/sas_data\")\n",
    "df_spark=spark.read.parquet(\"data/sas_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- i94yr: double (nullable = true)\n",
      " |-- i94mon: double (nullable = true)\n",
      " |-- i94cit: double (nullable = true)\n",
      " |-- i94res: double (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: double (nullable = true)\n",
      " |-- i94mode: double (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: double (nullable = true)\n",
      " |-- i94bir: double (nullable = true)\n",
      " |-- i94visa: double (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      " |-- dtadfile: string (nullable = true)\n",
      " |-- visapost: string (nullable = true)\n",
      " |-- occup: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- entdepu: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: double (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- insnum: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admnum: double (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      "\n",
      "+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "|    cicid| i94yr|i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|i94visa|count|dtadfile|visapost|occup|entdepa|entdepd|entdepu|matflag|biryear| dtaddto|gender|insnum|airline|        admnum|fltno|visatype|\n",
      "+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "|5749531.0|2016.0|   4.0| 251.0| 251.0|    NYC|20574.0|    1.0|     NV|20579.0|  42.0|    1.0|  1.0|20160430|     TLV| NULL|      G|      O|   NULL|      M| 1974.0|10292016|     F|  NULL|     DL|9.493188753E10|00469|      B1|\n",
      "|5749532.0|2016.0|   4.0| 251.0| 251.0|    NYC|20574.0|    1.0|     NV|20584.0|  40.0|    2.0|  1.0|20160430|     TLV| NULL|      G|      O|   NULL|      M| 1976.0|10292016|     F|  NULL|     DL|9.493207363E10|00469|      B2|\n",
      "|5749533.0|2016.0|   4.0| 251.0| 251.0|    NYC|20574.0|    1.0|     NV|20584.0|  39.0|    2.0|  1.0|20160430|     TLV| NULL|      G|      O|   NULL|      M| 1977.0|10292016|     M|  NULL|     DL|9.493197643E10|00469|      B2|\n",
      "|5749538.0|2016.0|   4.0| 251.0| 251.0|    NYC|20574.0|    1.0|     NY|   NULL|  23.0|    2.0|  1.0|20160430|     TLV| NULL|      G|   NULL|   NULL|   NULL| 1993.0|10292016|     M|  NULL|     EK|9.495134923E10|00203|      B2|\n",
      "|5749540.0|2016.0|   4.0| 251.0| 251.0|    NYC|20574.0|    1.0|     NY|20575.0|  39.0|    2.0|  1.0|20160430|     TLV| NULL|      G|      I|   NULL|      M| 1977.0|10292016|     M|  NULL|     PR|9.502525553E10|00126|      B2|\n",
      "+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#immegration dataset\n",
    "df_spark.printSchema()\n",
    "df_spark.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#World Temperature Data\n",
    "fname = '../../data2/GlobalLandTemperaturesByCity.csv'\n",
    "#df = pd.read_csv(fname)\n",
    "temperature_df = spark.read.option(\"header\", True).csv(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dt: string (nullable = true)\n",
      " |-- AverageTemperature: string (nullable = true)\n",
      " |-- AverageTemperatureUncertainty: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Latitude: string (nullable = true)\n",
      " |-- Longitude: string (nullable = true)\n",
      "\n",
      "+----------+------------------+-----------------------------+-----+-------+--------+---------+\n",
      "|        dt|AverageTemperature|AverageTemperatureUncertainty| City|Country|Latitude|Longitude|\n",
      "+----------+------------------+-----------------------------+-----+-------+--------+---------+\n",
      "|1743-11-01|             6.068|           1.7369999999999999|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1743-12-01|              NULL|                         NULL|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1744-01-01|              NULL|                         NULL|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1744-02-01|              NULL|                         NULL|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1744-03-01|              NULL|                         NULL|Århus|Denmark|  57.05N|   10.33E|\n",
      "+----------+------------------+-----------------------------+-----+-------+--------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temperature_df.printSchema()\n",
    "temperature_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Framingham</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>40.3</td>\n",
       "      <td>35442.0</td>\n",
       "      <td>35768.0</td>\n",
       "      <td>71210</td>\n",
       "      <td>2625.0</td>\n",
       "      <td>19070.0</td>\n",
       "      <td>2.49</td>\n",
       "      <td>MA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>6944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Waco</td>\n",
       "      <td>Texas</td>\n",
       "      <td>29.3</td>\n",
       "      <td>63452.0</td>\n",
       "      <td>68890.0</td>\n",
       "      <td>132342</td>\n",
       "      <td>10716.0</td>\n",
       "      <td>14235.0</td>\n",
       "      <td>2.57</td>\n",
       "      <td>TX</td>\n",
       "      <td>Asian</td>\n",
       "      <td>4230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fort Worth</td>\n",
       "      <td>Texas</td>\n",
       "      <td>32.6</td>\n",
       "      <td>414126.0</td>\n",
       "      <td>422843.0</td>\n",
       "      <td>836969</td>\n",
       "      <td>39182.0</td>\n",
       "      <td>143404.0</td>\n",
       "      <td>2.88</td>\n",
       "      <td>TX</td>\n",
       "      <td>American Indian and Alaska Native</td>\n",
       "      <td>7504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bellingham</td>\n",
       "      <td>Washington</td>\n",
       "      <td>30.7</td>\n",
       "      <td>41286.0</td>\n",
       "      <td>43857.0</td>\n",
       "      <td>85143</td>\n",
       "      <td>4703.0</td>\n",
       "      <td>8713.0</td>\n",
       "      <td>2.44</td>\n",
       "      <td>WA</td>\n",
       "      <td>American Indian and Alaska Native</td>\n",
       "      <td>2056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Maple Grove</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>38.6</td>\n",
       "      <td>31780.0</td>\n",
       "      <td>36601.0</td>\n",
       "      <td>68381</td>\n",
       "      <td>2943.0</td>\n",
       "      <td>7645.0</td>\n",
       "      <td>2.64</td>\n",
       "      <td>MN</td>\n",
       "      <td>White</td>\n",
       "      <td>59683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2886</th>\n",
       "      <td>Mesa</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>36.9</td>\n",
       "      <td>234998.0</td>\n",
       "      <td>236835.0</td>\n",
       "      <td>471833</td>\n",
       "      <td>31808.0</td>\n",
       "      <td>57492.0</td>\n",
       "      <td>2.68</td>\n",
       "      <td>AZ</td>\n",
       "      <td>White</td>\n",
       "      <td>413010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2887</th>\n",
       "      <td>Corpus Christi</td>\n",
       "      <td>Texas</td>\n",
       "      <td>35.0</td>\n",
       "      <td>160488.0</td>\n",
       "      <td>163594.0</td>\n",
       "      <td>324082</td>\n",
       "      <td>25078.0</td>\n",
       "      <td>30834.0</td>\n",
       "      <td>2.69</td>\n",
       "      <td>TX</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>200737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2888</th>\n",
       "      <td>Bismarck</td>\n",
       "      <td>North Dakota</td>\n",
       "      <td>38.0</td>\n",
       "      <td>34675.0</td>\n",
       "      <td>35565.0</td>\n",
       "      <td>70240</td>\n",
       "      <td>4145.0</td>\n",
       "      <td>2064.0</td>\n",
       "      <td>2.11</td>\n",
       "      <td>ND</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>1667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2889</th>\n",
       "      <td>Orem</td>\n",
       "      <td>Utah</td>\n",
       "      <td>26.1</td>\n",
       "      <td>48695.0</td>\n",
       "      <td>45762.0</td>\n",
       "      <td>94457</td>\n",
       "      <td>2828.0</td>\n",
       "      <td>12808.0</td>\n",
       "      <td>3.26</td>\n",
       "      <td>UT</td>\n",
       "      <td>American Indian and Alaska Native</td>\n",
       "      <td>976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2890</th>\n",
       "      <td>Lowell</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>33.4</td>\n",
       "      <td>54422.0</td>\n",
       "      <td>56298.0</td>\n",
       "      <td>110720</td>\n",
       "      <td>3764.0</td>\n",
       "      <td>33414.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>68838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2891 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                City          State  Median Age  Male Population  \\\n",
       "0         Framingham  Massachusetts        40.3          35442.0   \n",
       "1               Waco          Texas        29.3          63452.0   \n",
       "2         Fort Worth          Texas        32.6         414126.0   \n",
       "3         Bellingham     Washington        30.7          41286.0   \n",
       "4        Maple Grove      Minnesota        38.6          31780.0   \n",
       "...              ...            ...         ...              ...   \n",
       "2886            Mesa        Arizona        36.9         234998.0   \n",
       "2887  Corpus Christi          Texas        35.0         160488.0   \n",
       "2888        Bismarck   North Dakota        38.0          34675.0   \n",
       "2889            Orem           Utah        26.1          48695.0   \n",
       "2890          Lowell  Massachusetts        33.4          54422.0   \n",
       "\n",
       "      Female Population  Total Population  Number of Veterans  Foreign-born  \\\n",
       "0               35768.0             71210              2625.0       19070.0   \n",
       "1               68890.0            132342             10716.0       14235.0   \n",
       "2              422843.0            836969             39182.0      143404.0   \n",
       "3               43857.0             85143              4703.0        8713.0   \n",
       "4               36601.0             68381              2943.0        7645.0   \n",
       "...                 ...               ...                 ...           ...   \n",
       "2886           236835.0            471833             31808.0       57492.0   \n",
       "2887           163594.0            324082             25078.0       30834.0   \n",
       "2888            35565.0             70240              4145.0        2064.0   \n",
       "2889            45762.0             94457              2828.0       12808.0   \n",
       "2890            56298.0            110720              3764.0       33414.0   \n",
       "\n",
       "      Average Household Size State Code                               Race  \\\n",
       "0                       2.49         MA          Black or African-American   \n",
       "1                       2.57         TX                              Asian   \n",
       "2                       2.88         TX  American Indian and Alaska Native   \n",
       "3                       2.44         WA  American Indian and Alaska Native   \n",
       "4                       2.64         MN                              White   \n",
       "...                      ...        ...                                ...   \n",
       "2886                    2.68         AZ                              White   \n",
       "2887                    2.69         TX                 Hispanic or Latino   \n",
       "2888                    2.11         ND                 Hispanic or Latino   \n",
       "2889                    3.26         UT  American Indian and Alaska Native   \n",
       "2890                    2.80         MA                              White   \n",
       "\n",
       "       Count  \n",
       "0       6944  \n",
       "1       4230  \n",
       "2       7504  \n",
       "3       2056  \n",
       "4      59683  \n",
       "...      ...  \n",
       "2886  413010  \n",
       "2887  200737  \n",
       "2888    1667  \n",
       "2889     976  \n",
       "2890   68838  \n",
       "\n",
       "[2891 rows x 12 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#U.S. City Demographic Data\n",
    "us_cities_df = pd.read_csv('data/us-cities-demographics.csv', sep = ';')\n",
    "us_cities_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00A</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Total Rf Heliport</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-PA</td>\n",
       "      <td>Bensalem</td>\n",
       "      <td>00A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00A</td>\n",
       "      <td>-74.93360137939453, 40.07080078125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00AA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Aero B Ranch Airport</td>\n",
       "      <td>3435.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-KS</td>\n",
       "      <td>Leoti</td>\n",
       "      <td>00AA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AA</td>\n",
       "      <td>-101.473911, 38.704022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00AK</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Lowell Field</td>\n",
       "      <td>450.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Anchor Point</td>\n",
       "      <td>00AK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AK</td>\n",
       "      <td>-151.695999146, 59.94919968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00AL</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Epps Airpark</td>\n",
       "      <td>820.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AL</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>00AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AL</td>\n",
       "      <td>-86.77030181884766, 34.86479949951172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00AR</td>\n",
       "      <td>closed</td>\n",
       "      <td>Newport Hospital &amp; Clinic Heliport</td>\n",
       "      <td>237.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AR</td>\n",
       "      <td>Newport</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-91.254898, 35.6087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55070</th>\n",
       "      <td>ZYYK</td>\n",
       "      <td>medium_airport</td>\n",
       "      <td>Yingkou Lanqi Airport</td>\n",
       "      <td>0.0</td>\n",
       "      <td>AS</td>\n",
       "      <td>CN</td>\n",
       "      <td>CN-21</td>\n",
       "      <td>Yingkou</td>\n",
       "      <td>ZYYK</td>\n",
       "      <td>YKH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>122.3586, 40.542524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55071</th>\n",
       "      <td>ZYYY</td>\n",
       "      <td>medium_airport</td>\n",
       "      <td>Shenyang Dongta Airport</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AS</td>\n",
       "      <td>CN</td>\n",
       "      <td>CN-21</td>\n",
       "      <td>Shenyang</td>\n",
       "      <td>ZYYY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>123.49600219726562, 41.784400939941406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55072</th>\n",
       "      <td>ZZ-0001</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Sealand Helipad</td>\n",
       "      <td>40.0</td>\n",
       "      <td>EU</td>\n",
       "      <td>GB</td>\n",
       "      <td>GB-ENG</td>\n",
       "      <td>Sealand</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.4825, 51.894444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55073</th>\n",
       "      <td>ZZ-0002</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Glorioso Islands Airstrip</td>\n",
       "      <td>11.0</td>\n",
       "      <td>AF</td>\n",
       "      <td>TF</td>\n",
       "      <td>TF-U-A</td>\n",
       "      <td>Grande Glorieuse</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.296388888900005, -11.584277777799999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55074</th>\n",
       "      <td>ZZZZ</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Satsuma IÅjima Airport</td>\n",
       "      <td>338.0</td>\n",
       "      <td>AS</td>\n",
       "      <td>JP</td>\n",
       "      <td>JP-46</td>\n",
       "      <td>Mishima-Mura</td>\n",
       "      <td>RJX7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>130.270556, 30.784722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>55075 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ident            type                                name  \\\n",
       "0          00A        heliport                   Total Rf Heliport   \n",
       "1         00AA   small_airport                Aero B Ranch Airport   \n",
       "2         00AK   small_airport                        Lowell Field   \n",
       "3         00AL   small_airport                        Epps Airpark   \n",
       "4         00AR          closed  Newport Hospital & Clinic Heliport   \n",
       "...        ...             ...                                 ...   \n",
       "55070     ZYYK  medium_airport               Yingkou Lanqi Airport   \n",
       "55071     ZYYY  medium_airport             Shenyang Dongta Airport   \n",
       "55072  ZZ-0001        heliport                     Sealand Helipad   \n",
       "55073  ZZ-0002   small_airport           Glorioso Islands Airstrip   \n",
       "55074     ZZZZ   small_airport             Satsuma IÅjima Airport   \n",
       "\n",
       "       elevation_ft continent iso_country iso_region      municipality  \\\n",
       "0              11.0       NaN          US      US-PA          Bensalem   \n",
       "1            3435.0       NaN          US      US-KS             Leoti   \n",
       "2             450.0       NaN          US      US-AK      Anchor Point   \n",
       "3             820.0       NaN          US      US-AL           Harvest   \n",
       "4             237.0       NaN          US      US-AR           Newport   \n",
       "...             ...       ...         ...        ...               ...   \n",
       "55070           0.0        AS          CN      CN-21           Yingkou   \n",
       "55071           NaN        AS          CN      CN-21          Shenyang   \n",
       "55072          40.0        EU          GB     GB-ENG           Sealand   \n",
       "55073          11.0        AF          TF     TF-U-A  Grande Glorieuse   \n",
       "55074         338.0        AS          JP      JP-46      Mishima-Mura   \n",
       "\n",
       "      gps_code iata_code local_code                              coordinates  \n",
       "0          00A       NaN        00A       -74.93360137939453, 40.07080078125  \n",
       "1         00AA       NaN       00AA                   -101.473911, 38.704022  \n",
       "2         00AK       NaN       00AK              -151.695999146, 59.94919968  \n",
       "3         00AL       NaN       00AL    -86.77030181884766, 34.86479949951172  \n",
       "4          NaN       NaN        NaN                      -91.254898, 35.6087  \n",
       "...        ...       ...        ...                                      ...  \n",
       "55070     ZYYK       YKH        NaN                      122.3586, 40.542524  \n",
       "55071     ZYYY       NaN        NaN   123.49600219726562, 41.784400939941406  \n",
       "55072      NaN       NaN        NaN                        1.4825, 51.894444  \n",
       "55073      NaN       NaN        NaN  47.296388888900005, -11.584277777799999  \n",
       "55074     RJX7       NaN        NaN                    130.270556, 30.784722  \n",
       "\n",
       "[55075 rows x 12 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Airport Code Table\n",
    "airport_codes_df = pd.read_csv('data/airport-codes_csv.csv')\n",
    "airport_codes_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc.\n",
    "\n",
    "#### Cleaning Steps\n",
    "Document steps necessary to clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing cleaning tasks here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "Map out the conceptual data model and explain why you chose that model\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "List the steps necessary to pipeline the data into the chosen data model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform quality checks here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Data dictionary \n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "* Propose how often the data should be updated and why.\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    " * The database needed to be accessed by 100+ people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
